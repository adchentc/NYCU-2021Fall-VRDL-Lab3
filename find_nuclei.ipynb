{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_NYCU_VRDL_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Check if GPU is using"
      ],
      "metadata": {
        "id": "RibyULjlLho1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "hmDS_Kix4seu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsePPpwZSmqt"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset"
      ],
      "metadata": {
        "id": "2vFgr0AQrGNK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb"
      },
      "source": [
        "# download, decompress the data\n",
        "!gdown --id '1DEBaNwc1vEPdy5VQfw52rmUNAnHdp8iH' --output dataset.zip\n",
        "!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbAM2pv-urF"
      },
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_train\", {}, \"/content/dataset/train_correct.json\", \"/content/dataset/train\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train!"
      ],
      "metadata": {
        "id": "Wb-K20BELRyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to use pre-trained weight with iters 3000 which I had already trained\n",
        "# Open 'OPEN' blocks and Close 'CLOSE' block\n",
        "\n",
        "############################# OPEN ###################################\n",
        "\n",
        "# !gdown --id '1jYZjdhSUQwXJlZneBRU5hg0HSyHxpViL' --output pre_weights.zip\n",
        "# !unzip pre_weights.zip\n",
        "\n",
        "# !mkdir output\n",
        "# !mv model_iters_3300.pth output\n",
        "\n",
        "######################################################################"
      ],
      "metadata": {
        "id": "TsWmJgvGnmnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.config import LazyConfig, instantiate\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "############################ CLOSE ###################################\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "\n",
        "######################################################################\n",
        "\n",
        "############################# OPEN ###################################\n",
        "\n",
        "# cfg.MODEL.WEIGHTS = os.path.join('output', \"model_iters_3300.pth\")\n",
        "\n",
        "######################################################################\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.0005  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300 \n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "4mZwSgVVgyFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test!\n",
        "\n",
        "Now, let's start testing!\n"
      ],
      "metadata": {
        "id": "hvHtm77IcBvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv\n",
        "\n",
        "import pycocotools._mask as _mask\n",
        "import os\n",
        "import cv2\n",
        "import mmcv\n",
        "import json\n",
        "import pycocotools.mask as mask_util\n",
        "from detectron2.structures import Boxes, BoxMode"
      ],
      "metadata": {
        "id": "EtkA2fuc0luE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def instances_to_coco_json(instances, img_id):\n",
        "    \"\"\"\n",
        "    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n",
        "\n",
        "    Args:\n",
        "        instances (Instances):\n",
        "        img_id (int): the image id\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: list of json annotations in COCO format.\n",
        "    \"\"\"\n",
        "    num_instance = len(instances)\n",
        "    if num_instance == 0:\n",
        "        return []\n",
        "\n",
        "    boxes = instances.pred_boxes.tensor.cpu().numpy()\n",
        "    boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n",
        "    boxes = boxes.tolist()\n",
        "    scores = instances.scores.tolist()\n",
        "    classes = instances.pred_classes.tolist()\n",
        "    has_mask = instances.has(\"pred_masks\")\n",
        "    if has_mask:\n",
        "        # use RLE to encode the masks, because they are too large and takes memory\n",
        "        # since this evaluator stores outputs of the entire dataset\n",
        "        rles = [\n",
        "            mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n",
        "            for mask in instances.pred_masks.cpu()\n",
        "        ]\n",
        "        for rle in rles:\n",
        "            # \"counts\" is an array encoded by mask_util as a byte-stream. Python3's\n",
        "            # json writer which always produces strings cannot serialize a bytestream\n",
        "            # unless you decode it. Thankfully, utf-8 works out (which is also what\n",
        "            # the pycocotools/_mask.pyx does).\n",
        "            rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
        "\n",
        "    has_keypoints = instances.has(\"pred_keypoints\")\n",
        "    if has_keypoints:\n",
        "        keypoints = instances.pred_keypoints\n",
        "\n",
        "    results = []\n",
        "    for k in range(num_instance):\n",
        "        result = {\n",
        "            \"image_id\": img_id,\n",
        "            \"category_id\": classes[k] + 1,\n",
        "            \"bbox\": boxes[k],\n",
        "            \"score\": scores[k],\n",
        "        }\n",
        "        if has_mask:\n",
        "            result[\"segmentation\"] = rles[k]\n",
        "        if has_keypoints:\n",
        "            # In COCO annotations,\n",
        "            # keypoints coordinates are pixel indices.\n",
        "            # However our predictions are floating point coordinates.\n",
        "            # Therefore we subtract 0.5 to be consistent with the annotation format.\n",
        "            # This is the inverse of data loading logic in `datasets/coco.py`.\n",
        "            keypoints[k][:, :2] -= 0.5\n",
        "            result[\"keypoints\"] = keypoints[k].flatten().tolist()\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "def write_answer(annotations, im, img_id):\n",
        "    outputs = predictor(im)\n",
        "    instances = outputs['instances']\n",
        "    # print(instances)\n",
        "    results_per_img = instances_to_coco_json(instances, img_id)\n",
        "    annotations = annotations + results_per_img\n",
        "    print(len(annotations))\n",
        "    return annotations"
      ],
      "metadata": {
        "id": "duZnLaDbnrHs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = []\n",
        "folder = '/content/dataset/test'\n",
        "\n",
        "with open('/content/dataset/test_img_ids.json') as f:\n",
        "  test_info = json.load(f)\n",
        "\n",
        "for file_name in os.listdir(folder):\n",
        "  correct_item = next(item for item in test_info if item[\"file_name\"] == file_name)\n",
        "  im_path = os.path.join(folder, file_name)\n",
        "  im = cv2.imread(im_path)\n",
        "  annotations = write_answer(annotations, im, img_id=correct_item[\"id\"])\n",
        "  print(file_name, correct_item[\"id\"])\n",
        "\n",
        "mmcv.dump(annotations, 'answer.json', indent=4)"
      ],
      "metadata": {
        "id": "4TMdBeclk_Ye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}